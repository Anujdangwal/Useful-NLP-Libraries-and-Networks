{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "f9dcf52182564cb8b2acb87a1bd02eb7",
      "4b7c70a6e3f344cf94e3cfd42ec0a71e",
      "019b8a45674a401a88ebab947392b756"
     ]
    },
    "id": "SJWYosOceNqj",
    "outputId": "76ca998a-efb8-47f5-cf45-070279ed2598"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9dcf52182564cb8b2acb87a1bd02eb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "widgets.IntSlider()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vOxxFNglZQ_v"
   },
   "source": [
    "# NLP & Deep Learning Concepts — Comprehensive Overview\n",
    "\n",
    "---\n",
    "\n",
    "### 1. What is NLTK?  \n",
    "**NLTK (Natural Language Toolkit)** is a popular Python library that provides a wide range of tools for natural language processing. It includes modules for tokenization, part-of-speech tagging, parsing, stemming, and access to many linguistic corpora. NLTK is mainly used for research and educational purposes.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. What is SpaCy and how does it differ from NLTK?  \n",
    "**spaCy** is an industrial-strength NLP library designed for speed and efficiency. It comes with pre-trained models optimized for real-world applications. Compared to NLTK, spaCy is faster, easier to use in production, and better suited for handling large-scale NLP tasks, while NLTK is more focused on teaching and prototyping.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. What is the purpose of TextBlob in NLP?  \n",
    "**TextBlob** is a simple Python library built on top of NLTK and Pattern. It provides easy-to-use APIs for common NLP tasks such as sentiment analysis, part-of-speech tagging, noun phrase extraction, and translation. It is ideal for beginners and quick prototyping.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. What is Stanford NLP?  \n",
    "**Stanford NLP (CoreNLP)** is a powerful Java-based toolkit developed by Stanford University. It offers state-of-the-art models for various NLP tasks like POS tagging, parsing, named entity recognition, coreference resolution, and sentiment analysis. Python wrappers such as Stanza allow easy integration.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Explain what Recurrent Neural Networks (RNN) are  \n",
    "**RNNs** are neural networks designed to process sequential data by maintaining a hidden state that captures information from previous time steps. This memory-like property allows them to model temporal dependencies in data such as text, speech, and time series.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. What is the main advantage of using LSTM over RNN?  \n",
    "**LSTM (Long Short-Term Memory)** networks solve the vanishing gradient problem that traditional RNNs face by using gating mechanisms (input, forget, output gates) to control information flow. This enables LSTMs to remember long-term dependencies more effectively.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. What are Bi-directional LSTMs, and how do they differ from standard LSTMs?  \n",
    "**Bi-directional LSTMs** process input sequences in both forward and backward directions, capturing context from past and future tokens. Standard LSTMs process sequences only forward, limiting their understanding of context.\n",
    "\n",
    "---\n",
    "\n",
    "### 8. What is the purpose of a Stacked LSTM?  \n",
    "A **Stacked LSTM** consists of multiple LSTM layers stacked on top of each other. This deep architecture allows the network to learn hierarchical and more complex temporal features, improving its ability to model sophisticated sequence patterns.\n",
    "\n",
    "---\n",
    "\n",
    "### 9. How does a GRU (Gated Recurrent Unit) differ from an LSTM?  \n",
    "**GRUs** simplify the LSTM architecture by combining the forget and input gates into a single update gate and merging the cell state and hidden state. This results in fewer parameters, faster training, and often comparable performance.\n",
    "\n",
    "---\n",
    "\n",
    "### 10. What are the key features of NLTK's tokenization process?  \n",
    "NLTK offers versatile tokenizers that can split text into sentences or words. It handles punctuation, contractions, and supports regex-based tokenization. NLTK also provides multilingual tokenization support.\n",
    "\n",
    "---\n",
    "\n",
    "### 11. How do you perform named entity recognition (NER) using SpaCy?  \n",
    "To perform NER with spaCy:  \n",
    "- Load a pre-trained model (e.g., `en_core_web_sm`)  \n",
    "- Process your text using `nlp()`  \n",
    "- Extract entities via `doc.ents`, which provide the entity text and type (like PERSON, ORG, GPE)\n",
    "\n",
    "---\n",
    "\n",
    "### 12. What is Word2Vec and how does it represent words?  \n",
    "**Word2Vec** is a neural embedding model that represents words as dense, continuous vectors in a high-dimensional space. It captures semantic relationships between words by training on the context in which words appear using models like CBOW or Skip-gram.\n",
    "\n",
    "---\n",
    "\n",
    "### 13. Explain the difference between Bag of Words (BoW) and Word2Vec  \n",
    "- **Bag of Words (BoW):** Represents text as sparse vectors counting word occurrences, ignoring order and semantics.  \n",
    "- **Word2Vec:** Produces dense vector representations capturing semantic meaning and relationships between words.\n",
    "\n",
    "---\n",
    "\n",
    "### 14. How does TextBlob handle sentiment analysis?  \n",
    "TextBlob uses a lexicon-based approach that assigns polarity and subjectivity scores to text by referencing predefined sentiment values for words and phrases.\n",
    "\n",
    "---\n",
    "\n",
    "### 15. How would you implement text preprocessing using NLTK?  \n",
    "Typical preprocessing steps include:  \n",
    "- Tokenizing text into words or sentences  \n",
    "- Lowercasing all words  \n",
    "- Removing stopwords  \n",
    "- Applying stemming or lemmatization  \n",
    "- Optionally tagging parts of speech for more context-aware processing\n",
    "\n",
    "---\n",
    "\n",
    "### 16. How do you train a custom NER model using SpaCy?  \n",
    "To train a custom NER model:  \n",
    "- Prepare annotated training data with entities labeled  \n",
    "- Initialize or update SpaCy’s NER pipeline component  \n",
    "- Train the model through multiple iterations with an optimizer  \n",
    "- Save and load the trained model for future use\n",
    "\n",
    "---\n",
    "\n",
    "### 17. What is the role of the attention mechanism in LSTMs and GRUs?  \n",
    "Attention allows models to focus selectively on different parts of the input sequence when generating outputs. This improves performance on complex or long sequences by dynamically weighting important information.\n",
    "\n",
    "---\n",
    "\n",
    "### 18. What is the difference between tokenization and lemmatization in NLP?  \n",
    "- **Tokenization:** Splits text into smaller units called tokens (words, sentences).  \n",
    "- **Lemmatization:** Reduces tokens to their base or dictionary form (lemma), considering the word's context and part of speech.\n",
    "\n",
    "---\n",
    "\n",
    "### 19. How do you perform text normalization in NLP?  \n",
    "Text normalization typically involves:  \n",
    "- Lowercasing text  \n",
    "- Removing punctuation and special characters  \n",
    "- Eliminating stopwords  \n",
    "- Correcting misspellings  \n",
    "- Applying stemming or lemmatization\n",
    "\n",
    "---\n",
    "\n",
    "### 20. What is the purpose of frequency distribution in NLP?  \n",
    "Frequency distribution counts how often words or tokens occur in a corpus. It helps understand text characteristics, identify important words, and filter rare or overly common terms.\n",
    "\n",
    "---\n",
    "\n",
    "### 21. What are co-occurrence vectors in NLP?  \n",
    "Co-occurrence vectors record how often pairs of words appear near each other within a context window. They capture semantic relationships and are used in models like GloVe for word embeddings.\n",
    "\n",
    "---\n",
    "\n",
    "### 22. How is Word2Vec used to find the relationship between words?  \n",
    "Word2Vec captures semantic relationships by measuring cosine similarity between vectors. It can perform analogies like:  \n",
    "*king - man + woman ≈ queen*\n",
    "\n",
    "---\n",
    "\n",
    "### 23. How does a Bi-LSTM improve NLP tasks compared to a regular LSTM?  \n",
    "Bi-LSTMs use context from both past and future tokens, which provides a richer understanding of the sequence and enhances performance on tasks like NER and speech recognition.\n",
    "\n",
    "---\n",
    "\n",
    "### 24. What is the difference between a GRU and an LSTM in terms of gate structures?  \n",
    "- **LSTM:** Has three gates — input, forget, and output — to control the flow of information.  \n",
    "- **GRU:** Has two gates — reset and update — combining functions to simplify the architecture.\n",
    "\n",
    "---\n",
    "\n",
    "### 25. How does Stanford NLP’s dependency parsing work?  \n",
    "Dependency parsing analyzes grammatical relations between words to form a tree structure representing syntactic dependencies like subjects, objects, and modifiers.\n",
    "\n",
    "---\n",
    "\n",
    "### 26. How does tokenization affect downstream NLP tasks?  \n",
    "Accurate tokenization ensures meaningful input units for subsequent tasks like tagging, parsing, and classification. Poor tokenization can reduce model performance significantly.\n",
    "\n",
    "---\n",
    "\n",
    "### 27. What are some common applications of NLP?  \n",
    "- Chatbots and virtual assistants  \n",
    "- Sentiment analysis  \n",
    "- Machine translation  \n",
    "- Text summarization  \n",
    "- Speech recognition  \n",
    "- Information extraction  \n",
    "- Question answering systems\n",
    "\n",
    "---\n",
    "\n",
    "### 28. What are stopwords and why are they removed in NLP?  \n",
    "Stopwords are very common words (e.g., \"the,\" \"is,\" \"and\") that carry little meaning. Removing them reduces noise and focuses models on the more informative parts of the text.\n",
    "\n",
    "---\n",
    "\n",
    "### 29. How can you implement word embeddings using Word2Vec in Python?  \n",
    "Using `gensim`:  \n",
    "```python\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52pOAeA7aSXn"
   },
   "source": [
    "30. How does SpaCy handle lemmatization?\n",
    "* SpaCy uses a combination of rule-based lookups and statistical models informed by part-of-speech tagging to accurately reduce words to their lemmas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_75zokL9aUOY"
   },
   "source": [
    "31. What is the significance of RNNs in NLP tasks?\n",
    "* RNNs allow models to capture temporal dependencies in sequential data, which is essential for understanding and generating natural language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gSAFEaCXaZAg"
   },
   "source": [
    "32. How does word embedding improve the performance of NLP models?\n",
    "* Word embeddings encode semantic similarity in dense vector spaces, enabling models to generalize better by recognizing related concepts even if exact words differ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unKQyXi_abt6"
   },
   "source": [
    "33. How does a Stacked LSTM differ from a single LSTM?\n",
    "\n",
    "* Stacked LSTMs have multiple layers stacked vertically, which allows the model to learn increasingly abstract temporal features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fYoABHLsag1z"
   },
   "source": [
    "### 34. What are the key differences between RNN, LSTM, and GRU?\n",
    "\n",
    "| Model | Key Characteristics |\n",
    "|-------|---------------------|\n",
    "| **RNN**   | Basic recurrent structure, struggles with long-term dependencies due to vanishing gradients. |\n",
    "| **LSTM**  | Uses input, forget, and output gates to manage memory, effectively handles long-term dependencies. |\n",
    "| **GRU**   | Simplified LSTM with reset and update gates, fewer parameters, faster training while maintaining performance. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HnFf5SpKau5E"
   },
   "source": [
    "35. Why is the attention mechanism important in sequence-to-sequence models?\n",
    "* Attention lets the model dynamically focus on relevant parts of the input sequence when generating each output token, greatly improving performance on tasks like translation and summarization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIVB9Jsza0e-"
   },
   "source": [
    "# Practical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lrTx8JKSa9u_"
   },
   "source": [
    "1. How do you perform word tokenization using NLTK and plot a word frequency distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "id": "Ch1ilacPZT5K",
    "outputId": "2faf1523-5bc3-4f61-c7f8-0207fa0a6428"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "import matplotlib.pyplot as plt\n",
    "nltk.download(\"punkt_tab\")\n",
    "\n",
    "text = \"Your sample text goes here. here\"\n",
    "tokens = word_tokenize(text.lower())\n",
    "freq_dist = FreqDist(tokens)\n",
    "\n",
    "freq_dist.plot(30, cumulative=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1FT5BPTlbTHj"
   },
   "source": [
    "2. How do you use SpaCy for dependency parsing of a sentence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pdFZFM60a8sK",
    "outputId": "4a208c5c-5e26-46a2-c5fd-91a0c8942549"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The --> det --> fox\n",
      "quick --> amod --> fox\n",
      "brown --> amod --> fox\n",
      "fox --> nsubj --> jumps\n",
      "jumps --> ROOT --> jumps\n",
      "over --> prep --> jumps\n",
      "the --> det --> dog\n",
      "lazy --> amod --> dog\n",
      "dog --> pobj --> over\n",
      ". --> punct --> jumps\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"The quick brown fox jumps over the lazy dog.\")\n",
    "\n",
    "for token in doc:\n",
    "    print(f\"{token.text} --> {token.dep_} --> {token.head.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShdNOZtibgxL"
   },
   "source": [
    "3.  How do you use TextBlob for performing text classification based on polarity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UqORynsObi2L",
    "outputId": "4b923111-6e41-4a81-c2d5-badc5a93e6fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "text = \"I love this movie, it was fantastic!\"\n",
    "blob = TextBlob(text)\n",
    "polarity = blob.sentiment.polarity\n",
    "\n",
    "if polarity > 0:\n",
    "    print(\"Positive\")\n",
    "elif polarity == 0:\n",
    "    print(\"Neutral\")\n",
    "else:\n",
    "    print(\"Negative\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-cX49bTDbvMc"
   },
   "source": [
    "4. How do you extract named entities from a text using SpaCy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UshpuHxBbwfn",
    "outputId": "24033790-5e60-40c9-9257-19bf9c5ca71e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "U.K. GPE\n",
      "$1 billion MONEY\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion.\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3OsLpZ6b1Uk"
   },
   "source": [
    "5. How can you calculate TF-IDF scores for a given text using Scikit-learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fiTFald6b3Wg",
    "outputId": "7d1bef5b-68c0-4c78-8952-74aaa55f17d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['another' 'document' 'example' 'is' 'sample' 'this']\n",
      "[[0.         0.44832087 0.         0.44832087 0.63009934 0.44832087]\n",
      " [0.53309782 0.37930349 0.53309782 0.37930349 0.         0.37930349]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "documents = [\"This is a sample document.\", \"This document is another example.\"]\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(tfidf_matrix.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bzHc2S65b8gD"
   },
   "source": [
    "6. How do you create a custom text classifier using NLTK's Naive Bayes classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W8EzZvG4b5mr",
    "outputId": "30cbbdf6-aafe-46e6-a572-7463485ded8c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79\n",
      "Most Informative Features\n",
      "   contains(outstanding) = True              pos : neg    =     11.2 : 1.0\n",
      "         contains(mulan) = True              pos : neg    =      8.2 : 1.0\n",
      "        contains(seagal) = True              neg : pos    =      7.9 : 1.0\n",
      "   contains(wonderfully) = True              pos : neg    =      6.8 : 1.0\n",
      "         contains(damon) = True              pos : neg    =      6.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "import random\n",
    "nltk.download('movie_reviews')\n",
    "\n",
    "# Prepare data\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "random.shuffle(documents)\n",
    "\n",
    "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
    "word_features = list(all_words)[:2000]\n",
    "\n",
    "def document_features(document):\n",
    "    words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features[f'contains({word})'] = (word in words)\n",
    "    return features\n",
    "\n",
    "featuresets = [(document_features(d), c) for (d, c) in documents]\n",
    "train_set, test_set = featuresets[100:], featuresets[:100]\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))\n",
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lkKLE-U7cHPE"
   },
   "source": [
    "7. How do you use a pre-trained model from Hugging Face for text classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347,
     "referenced_widgets": [
      "3100e4ab693e4f05b4325ae273f56d30",
      "51c782441f8141b1a572ba5e520db2b0",
      "d95bf64e534d46b9b3b76084e057f557",
      "a7d88a5a0a27428c9840a3155201d8ac",
      "e89bb48f0ccc4f8da8b66b79927bb3ea",
      "42c969d14fc74c3cb88a8cd4f97b3742",
      "a1c4742e0410496a8a2a9d57a809cc02",
      "0a1ac258a42d493b97855ff8ed656cbe",
      "a281734cdf374cce88b26cc5686c83d0",
      "07fdc50e44094b649e33365d063b3198",
      "4eb501070f1e42d296b1ffe9b73a8cb0",
      "563535a269a84c28830b8e9f9ca5a890",
      "13da6c0a5cdc4228a4aa577c71e0ccf9",
      "306fae6de00e491ba308948a13ed3e58",
      "e11c54a99da546a8b78c5ad7fb0c7d51",
      "5a8f9fdda6944db19198191a5d0dfbdf",
      "4e324ab13a604f79ab8c3bf373f23944",
      "8ffc319e05d340ff807f4ad8394abdb0",
      "3c0bd4df529a4ce0b99a258c136e8a23",
      "2149bb5f5035411ebdd6741ad0fa8ae7",
      "5967819153e6469383ae47f59c346651",
      "31e33a7ca8f44ea8a409d1875145248a",
      "3ed0778ffd4a4d24805d6a742023b1ce",
      "aadcf29631d146299073be14f181114d",
      "0ea885db109041d3aee117c991a2d805",
      "974117571e7d4e4d99bcc20c2e7163a8",
      "a783675f4fd94932ba19697cd1ab0b9e",
      "769c53245ad54276a67a3383a744c1f1",
      "12cbe862c4eb4364a3d45c9c5bf62b69",
      "33bdbecac865454fa27a7ef56583decc",
      "702bae13f2204bfab85b0e6461ceb622",
      "9a652a43725c430296bd367bdf55b5a7",
      "4575a14344c84b99b08bafecccf79db7",
      "b9e1a025bed74f3e9bd4550d9886334f",
      "f66c2d6a11cb46109db1fa9d6258f281",
      "b4bce57965824eea975cc3913f03c623",
      "6ec88e5ad22b4c0e881a5b239dc68ddd",
      "fad430f0baaa4033b28a9d618df27603",
      "8f0e992ecba84d92b725ab5f64ea66b3",
      "4f2dbd8ca36b443281099bc0fc9bf3ba",
      "2052595d89e94d0e8e5d3eaed0e04562",
      "8f7be3e248104747a248bd00b5e7311d",
      "eeb324a1c9a442458fbf90729385ab80",
      "65dae125aae04cf69a4a8eecd726dade"
     ]
    },
    "id": "0nhTqnuvcBrB",
    "outputId": "5a0e19a0-b457-4957-bf22-5f618aa7e485"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3100e4ab693e4f05b4325ae273f56d30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563535a269a84c28830b8e9f9ca5a890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ed0778ffd4a4d24805d6a742023b1ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e1a025bed74f3e9bd4550d9886334f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9998855590820312}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "result = classifier(\"I love this product!\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzLfE0hjcRUx"
   },
   "source": [
    "8.  How do you perform text summarization using Hugging Face transformers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320,
     "referenced_widgets": [
      "0adf164a0fa54a1bbb9a3d9e0e9dc3f6",
      "6ad179d8b7f540b09b471b8446628bf5",
      "6032e909131a43be9843c3b11134402c",
      "979a05be2b944c53aeb87284048f217f",
      "4d79600559e44b8286538961cf679f95",
      "ec049a197ce14cbfa2b7b992db71a041",
      "ce3d38a2a4d44f13a868a95266bf9f15",
      "38da5436f8874a0eb3b11894dd3c772f",
      "ff5131a37c5c4beb8ece5a2690124086",
      "09beeed760b3418c9ef7d07cf287b77d",
      "9433ed855be6424da1fd55bb05e045c9",
      "08f5c68915304673897f8f72797a2236",
      "0b8c00fc6f0e4378973f93f3a5e57214",
      "6488beea92e74ec99e9804c10b5f17a8",
      "ff2e9ecd58bb4178b3181a936eeddb88",
      "a9ddccfb009147e1a619f49bcba4f7bd",
      "558812dde59c484f8b8ad6ac41e759fb",
      "cad05270c7b54cd38c9683355c5602d8",
      "2a092383d557449fa803fd7fbbbe3167",
      "6c7e0f38fdef471ea149e7b203be213d",
      "14f6f0b3848c42f4b1a10f4f74cef8e9",
      "ba5116502822455cb88174a5b35c730a",
      "d5be315e27494faf8134ec844156dbf6",
      "2d19b045cba547748535123b0852ed89",
      "90f24b82c0664d298eea30b485e55faa",
      "de0ac7133be143658f99b126b02ce64f",
      "02d20b2992f74013b35caff9bf13246b",
      "71e20a5b38084f768fa2fc9592efb867",
      "b1c3e785d21949a39778dceae9f2e032",
      "251a4e644acd40e88f7ffe31f726da25",
      "7eac5db93f9f4728b3376a949cd0ac9c",
      "7f60ef16f4324a63ab831424c8c79ee2",
      "bde4742a966b47c6b98c4e0f35d60fa7",
      "7a3380912bf849d58e401fc56889396a",
      "c4c06955bf5f44acbcc6bb2cfa0a7724",
      "d520239f90b54f65a5d502befc3da01f",
      "28946b44bbcb444398afc9dec5442b80",
      "2333941451d84098a107836f4555ee75",
      "a01a8763a717490395755b199c10cfc6",
      "48df51ee06314ba49c0ac2434757feb6",
      "cbd5d3409db84642b58b6a0f305b0b94",
      "e1421b1a49354431aae5331c9412cd5a",
      "d4536472b4ed43adbc3ff4d30239f3d2",
      "71792384b7aa40f599ddc50e77d738e1",
      "473de81c6f99497eaa414e8fe23c38b1",
      "4e786f64ff0d4ab6b78f5c4e4fcca4dc",
      "8e46e43d6bb545ea877cfe44c4b718e4",
      "3a8d5197516e47c8b5df7743f8e739fe",
      "bb6b9cbc3510407f8d3b5f0320a11571",
      "f94e1a9139eb48c098b8d87814e7bef6",
      "2d3a7e0286874eb5b55e810c56958ce8",
      "b4c8d3d0bf6d43f5a971df4c5e09e673",
      "d31e32a996cb4a29bad285ba8dc56763",
      "08a0645708c74003b7866b9c96c9bc11",
      "38862566a63a4835897561007687557f",
      "5f5fe2694e56435286dbeacc0017884b",
      "7cd79650dac6462da9caa3747979149d",
      "9c35348a5461452a839a741c3809c2f1",
      "85dd8182d9544c40a1efd63b7ec995c6",
      "5c62ec2855f14e84aac4d9c8d94a2ca1",
      "284b334bbad145548932c1f73283afc9",
      "9591c81f15e64420a34a3340352369ee",
      "80b412097a704b4cb66373c80c1672ce",
      "d98e9e54c55248c1a255947d173e41ea",
      "71b72f5d44e64082a6d2f1493522ce3b",
      "6038f9516d5b4a27a963c5a0a33c5052"
     ]
    },
    "id": "kzg1VNJzcT4s",
    "outputId": "2f5fa42e-dec8-40fa-da5f-392cda5352f1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0adf164a0fa54a1bbb9a3d9e0e9dc3f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08f5c68915304673897f8f72797a2236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5be315e27494faf8134ec844156dbf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a3380912bf849d58e401fc56889396a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "473de81c6f99497eaa414e8fe23c38b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f5fe2694e56435286dbeacc0017884b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Your max_length is set to 50, but your input_length is only 9. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Long text you want to summarize. Long text . Long text. You want to be able to read. Read it here .\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\")\n",
    "text = \"\"\"Long text you want to summarize.\"\"\"\n",
    "summary = summarizer(text, max_length=50, min_length=25, do_sample=False)\n",
    "print(summary[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "llgK5AKgcWAv"
   },
   "source": [
    "9. How can you create a simple RNN for text classification using Keras?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "OJpe-i4scVPm",
    "outputId": "b10e724e-73d5-4a52-f2c9-9e6085bf1275"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=5000, output_dim=32, input_length=100),\n",
    "    SimpleRNN(32),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WD3ISWxJcbfH"
   },
   "source": [
    "10. How do you train a Bidirectional LSTM for text classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "NvA1DI4zca2R",
    "outputId": "7ddfb3fc-915f-424f-a00f-18a8a561cb51"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(5000, 64, input_length=100),\n",
    "    Bidirectional(LSTM(64)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8MMq_mricg2O"
   },
   "source": [
    "11. How do you implement GRU (Gated Recurrent Unit) for text classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "OBrqEq2KcgMB",
    "outputId": "5a042c9e-e5ed-4955-99ca-555049464089"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(5000, 64, input_length=100),\n",
    "    GRU(64),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQ6RrCX2cl_h"
   },
   "source": [
    "12. How do you implement a text generation model using LSTM with Keras?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "Z1O9FBuFck0K",
    "outputId": "2e4f04ba-4313-4963-f796-e90af0da1a20"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=64, input_length=50),\n",
    "    LSTM(128),\n",
    "    Dense(10000, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gwgAJVIHcqYo"
   },
   "source": [
    "13. How do you implement a simple Bi-directional GRU for sequence labeling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "KQY9VMwkcpn7",
    "outputId": "5d3f8d02-9508-45ba-b6a2-00490c28aef7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_2              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_7 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_4 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_2              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, GRU, TimeDistributed, Dense\n",
    "\n",
    "# Define number of output classes for sequence labeling (e.g., number of tags)\n",
    "num_classes = 10  # replace with your actual number of classes\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=5000, output_dim=64, input_length=100),  # Vocabulary size = 5000, embedding dim = 64, sequence length = 100\n",
    "    Bidirectional(GRU(64, return_sequences=True)),               # Bi-GRU layer with 64 units, outputs sequences\n",
    "    TimeDistributed(Dense(num_classes, activation='softmax'))   # TimeDistributed layer to apply Dense layer to each timestep\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
